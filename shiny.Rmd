---
title: "Text_Analysis_Vaksin"
author: "Adam & Naufal "
date: "20/01/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r required}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(twitteR, wordcloud, tm, tidyr, tidytext, syuzhet, ngram, NLP, RColorBrewer, RTextTools, e1071, caret, knitr)
```

```{r global}
library(shiny)
library(here)
library(vroom)
library(dplyr)
library(ggplot2)
library(plotly)
library(syuzhet)
library(twitteR)
library(ROAuth)
library(tm)
library(rtweet)
library(wordcloud)

setwd(dir = "E:\\adam\\kuliah\\sem 5\\prak DS\\New folder\\PROJECT DS")


twitter<- vroom("data-bersih_vaksin_1.csv")
tweet<- twitter$text
ui <- fluidPage(
    titlePanel("SENTIMENT ANALISIS VAKSIN"),
        mainPanel(
            
            tabsetPanel(type = "tabs",
                        tabPanel("Emotion", plotOutput("emotion")), 
                        # Plot
                        # Output Data Dalam Tabel
                        tabPanel("Wordcloud", plotOutput("Wordcloud")),
                        
                        tabPanel("Data dalam bahasa indonesia", DT::dataTableOutput('tbl'))
                        )
        )
    )
# SERVER
server <- function(input, output) {
    
    #///Output Data
    output$tbl = DT::renderDataTable({
        DT::datatable(twitter, options = list(lengthChange = FALSE))
    })
    
    
    #///Output Emotion
    output$emotion <- renderPlot({sentiment_dataset<-read.csv("data-bersih_vaksin.csv",stringsAsFactors = FALSE)

    review <-as.character(sentiment_dataset$text)

    get_nrc_sentiment('happy')
    get_nrc_sentiment('excitement')
    s<-get_nrc_sentiment(review)

    review_combine<-cbind(sentiment_dataset$text,s)
    par(mar=rep(3,4))
    barplot(colSums(s),col=rainbow(10),ylab='count',main='Sentiment Score kata vaksin')
    }, height=500)
    
    #///Output Wordcloud
    output$Wordcloud <- renderPlot({data_twitter<-readRDS('data_mentah_vaksin.rds')
    df_twitter=twListToDF(data_twitter)
    
    #cleaning data
    #hanya ambil tweet saja
    komen<-df_twitter$text
    komenc<-Corpus(VectorSource(komen))
    
    #hapus tanda baca, link url, huruf aneh, dan emoji
    removeURL <-function(x) gsub("http[^[:space:]]*", "", x)
    twitclean <-tm_map(komenc,removeURL)
    
    removeRT<-function(y) gsub("RT", "", y)
    twitclean<-tm_map(twitclean,removeRT)
    
    removeUN<-function(z) gsub("@\\w+", "", z)
    twitclean<-tm_map(twitclean,removeUN)
    
    remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
    twitclean <- tm_map(twitclean,remove.all)
    
    twitclean<-tm_map(twitclean, removePunctuation)
    twitclean<-tm_map(twitclean, tolower)
    
    removeVaksin<-function(x) gsub("vaksin", "", x)
    df_twitter_new<-tm_map(twitclean,removeVaksin)
    
    #membuat nilai untuk masing-masing kata
    {
      dtm<-TermDocumentMatrix(df_twitter_new)
      m<-as.matrix(dtm)
      v<-sort(rowSums(m),decreasing = TRUE)
      df_twitter_new<-data.frame(word=names(v),freq=v)
    }
    head(df_twitter_new,n=10)
    
    set.seed(1234) # for reproducibility 
    wordcloud(words = df_twitter_new$word, 
          freq = df_twitter_new$freq, 
          min.freq = 1,           
          max.words =200, 
          random.order=FALSE, 
          rot.per=0.35,            
          colors=brewer.pal(8, "Dark2"))
    
  })
    
    
}
shinyApp(ui = ui, server = server)
```

